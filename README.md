
# Chat App with Flask & React

This project is a chatbot application built with **Flask** (backend) and **React** (frontend). It supports multiple AI models, chat history management, and dynamic profile generation.

## ğŸš€ Features

* **Flask API** for AI chat models
* **React UI** with model selection & chat interface
* **Chat history management** per model
* **Dynamic model profiles** with avatars
* **Multi-character support** for AI models

---

## ğŸ“¦ Installation Guide

### 1ï¸âƒ£ **Requirements**

Before running the project, ensure you have the following installed:

* **Python 3.8+**
* **Node.js & npm**
* **Ollama** (Install from: [ollama.ai](https://ollama.ai/))

### 2ï¸âƒ£ **Project Setup**

#### Install dependencies

```sh
npm i  # Install dependencies in the root folder (for concurrently package)
```

### 3ï¸âƒ£ **Backend Setup (Flask API)**

#### Install dependencies

```sh
cd backend
python -m venv venv
source venv/bin/activate  # On Windows use: venv\Scripts\activate
pip install -r req.txt
```

#### Run the Flask server

```sh
python app.py
```

The API will be available at: `http://127.0.0.1:5000`

---

### 4ï¸âƒ£ **Frontend Setup (React UI)**

#### Install dependencies

```sh
cd frontend
npm install
```

#### Start the React app

```sh
npm run dev
```

The UI will be available at: `http://localhost:5173`

---

## ğŸ”— API Endpoints

### ğŸ“Œ **Model Management**

* `GET /models` â†’ Fetch list of available models
* `GET /profiles` â†’ Get all model profiles
* `GET /profiles/<model_name>` â†’ Get profile of a specific model

### ğŸ’¬ **Chat Functionality**

* `POST /chat` â†’ Send a message to a model
  * **Body:** `{ "model_name": "<model>", "prompt": "<message>" }`
  * **Response:** `{ "response": "AI's reply" }`
* `GET /history/load?model_name=<model>` â†’ Fetch chat history for a model

---

## ğŸ“œ Project Structure

```
backend/
â”‚â”€â”€ app.py          # Flask backend
â”‚â”€â”€ data/           # Stores chat history & profiles
â”‚   â”œâ”€â”€ chat_histories/   # Folder for chat history JSONs
â”‚   â”œâ”€â”€ profile.json      # Stores model profiles
â”‚â”€â”€ req.txt         # Backend dependencies
â”‚â”€â”€ venv/           # Virtual environment

frontend/
â”‚â”€â”€ node_modules/   # Installed dependencies
â”‚â”€â”€ public/         # Static assets
â”‚â”€â”€ src/            # Source code
â”‚   â”œâ”€â”€ assets/     # Images & static files
â”‚   â”œâ”€â”€ Pages/      # Page components
â”‚   â”‚   â”œâ”€â”€ ChatApp.jsx   # Chat UI component
â”‚   â”‚   â”œâ”€â”€ Components.jsx # UI Components
â”‚   â”‚   â”œâ”€â”€ App.jsx       # Main React entry
â”‚   â”œâ”€â”€ index.css   # Global styles
â”‚   â”œâ”€â”€ main.jsx    # React main entry
â”‚â”€â”€ package.json    # Frontend dependencies
â”‚â”€â”€ vite.config.js  # Vite configuration
â”‚â”€â”€ index.html      # Main HTML file
â”‚â”€â”€ .gitignore      # Git ignore file
â”‚â”€â”€ eslint.config.js # Linting configuration
```

---

## ğŸ¯ Usage

1. Install **Ollama** and dependencies.
2. Install dependencies in the root folder (`npm i`)
3. Start the Flask backend (`python app.py`)
4. Start the React frontend (`npm run dev`)
5. Open `http://localhost:5173` in your browser
6. Select a model and start chatting!

---

## ğŸ› ï¸ Future Enhancements

* **User authentication** for personalized chats
* **Multiple AI model providers**
* **Voice interaction support**

ğŸš€ **Happy Coding!**
